{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe654313",
   "metadata": {},
   "source": [
    "This is a simple recommnedation system algorithm that using matrix factorization. The main point is to find a Mu = N_users x N_embed and a Mn = N_movies x N_embed matrices such that Ratings ~ Mu x Mm.T which is a N_user x N_movies matrix with element (i,j) being the rating provided by user i for movie j.  \n",
    "I suggest to to look at this project by Google  \n",
    "https://developers.google.com/machine-learning/recommendation  \n",
    "to learn more about recommendation systems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import Tensor as TT\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "import os\n",
    "import os.path\n",
    "import pathlib\n",
    "from typing import Any, Callable, Optional, Sequence, Tuple, Union\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2711c",
   "metadata": {},
   "source": [
    "Load the data containing user_id, movie_id, rating and timestamp. Rename the columns accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24e771-9376-4363-b1e6-16cb215b0a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mratings = pd.read_csv('/home/giangi/Workspace/Data/ml-100k/u.data', sep='\\t', header=None)\n",
    "columns=['user_id','movie_id','rating','timestamp']\n",
    "mratings.columns = columns\n",
    "rating_ugrp = mratings.groupby('user_id')['rating']\n",
    "rating_mgrp = mratings.groupby('movie_id')['rating']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf0bd7",
   "metadata": {},
   "source": [
    "Check some stats on the number of ratings given by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "urating_cnt = rating_ugrp.count()\n",
    "urating_cnt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682a72d",
   "metadata": {},
   "source": [
    "Check some stats on the number of ratings received by movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0974e-7690-48fc-a848-d685f192cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrating_cnt = rating_mgrp.count()\n",
    "mrating_cnt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5f05d",
   "metadata": {},
   "source": [
    "Check some stats on the ratings given by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237f401-2153-4b7e-9d35-a8d851350c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "urating_avg = rating_ugrp.mean()\n",
    "urating_avg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b9f08",
   "metadata": {},
   "source": [
    "Check some stats on the ratings received by movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c44d1-3d87-45b7-aac4-6dba03b9dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrating_avg = rating_mgrp.mean()\n",
    "mrating_avg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddf69a",
   "metadata": {},
   "source": [
    "Use the user_id and movie_id as indeces of the factorized matrix M = Users_emb x Movies_emd.T. Subract one to make them zero based.  \n",
    "Do a random split of 80% training and 20% validation data.  \n",
    "Make the ratings zero-mean by subtracting the mean computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841d773-1932-4f2d-b114-884e684cb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the indices for users and movies. Make is zero base since they start from 1\n",
    "indices = mratings[['user_id','movie_id']].values - 1\n",
    "#shuffle the indices to create train and validation sets\n",
    "indx = np.arange(indices.shape[0])\n",
    "np.random.shuffle(indx)\n",
    "split_percent = 0.8\n",
    "split_train = int(round(split_percent*indx.size))\n",
    "indx_train = TT(indices[indx[:split_train]]).int()\n",
    "indx_val = TT(indices[indx[-(indx.size - split_train):]]).int()\n",
    "rate_train_orig = mratings['rating'].values.astype(float)[indx[:split_train]]\n",
    "rate_train = TT(rate_train_orig)\n",
    "avg_rate = rate_train.mean()\n",
    "rate_train -= avg_rate\n",
    "rate_val_orig = mratings['rating'].values.astype(float)[indx[-(indx.size - split_train):]]\n",
    "rate_val = TT(rate_val_orig)\n",
    "rate_val -= avg_rate#remove the train mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b38ca0",
   "metadata": {},
   "source": [
    "Perform a sanity check to make sure that the indeces used for training correspond to the correct original position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69d59b-7827-4497-b041-5873b0a057a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "all_good = True\n",
    "for _ in range(1000):\n",
    "    #get any original index\n",
    "    i = np.random.randint(len(indx_train))\n",
    "    #get the corresponding index in the training set\n",
    "    indx_now = indx_train[i].numpy()\n",
    "    #check that the ratings in the training set and original are the same \n",
    "    if rate_train_orig[i] != mratings.loc[(mratings['user_id'] - 1 == indx_now[0]) & (mratings['movie_id'] - 1 == indx_now[1])]['rating'].values[0]:\n",
    "        all_good = False\n",
    "all_good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88db00a",
   "metadata": {},
   "source": [
    "Create the loss and the model. For the loss, beside the mean square error between prediction and truth, we add a *L2* regularization term to ensure that the elements of the embedding are not too large and another regurarization term called *gravity* to make sure that the ratings predicted are not too large.  \n",
    "The model simply returns the user and the movie embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6321b-53a3-4cf4-aab5-f82ba411d3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFLoss(nn.Module):\n",
    "    def __init__(self,lambda_g,lambda_r):\n",
    "        super().__init__()\n",
    "        self.lambda_g = lambda_g\n",
    "        self.lambda_r = lambda_r\n",
    "    def forward(self,ratings,iuemb,imemb,indices_um,print_l=False):\n",
    "        uemb = iuemb.weight\n",
    "        memb = imemb.weight\n",
    "        approx = torch.matmul(uemb,memb.T)\n",
    "        #MSE loss\n",
    "        loss = ((approx[indices_um[:,0],indices_um[:,1]] - ratings)*(approx[indices_um[:,0],indices_um[:,1]] - ratings)).mean()\n",
    "        #L2 regularization loss \n",
    "        lossr = self.lambda_r*((uemb*uemb).sum()/uemb.shape[0] + (memb*memb).sum()/memb.shape[0])\n",
    "        #Gravity loss 1/(num_users*num_movies)sum_{i,j}(<uemb_i,memb_j>**2)\n",
    "        lossg = self.lambda_g*(approx*approx).sum()/(uemb.shape[0]*memb.shape[0])\n",
    "        if print_l:\n",
    "            print('Losses',loss.item(),lossr.item(),lossg.item())\n",
    "        return loss + lossr + lossg\n",
    "\n",
    "#Collaborative FilteringModel\n",
    "class CFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, emb_size):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.movie_emb = nn.Embedding(num_movies, emb_size)\n",
    "    \n",
    "    def forward(self):\n",
    "        return self.user_emb,self.movie_emb\n",
    "#Test loss\n",
    "# nemb = 100\n",
    "# uemb = nn.Embedding(nusers,nemb)\n",
    "# memb = nn.Embedding(nmovies,nemb)\n",
    "# lambda_g = 0.1\n",
    "# lambda_r = 0.1\n",
    "# cfloss = CFLoss(lambda_g,lambda_r)\n",
    "# cfloss(rate_train,uemb,memb,indx_train)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c54b9",
   "metadata": {},
   "source": [
    "Train the model using AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee338783-82fa-4a0d-85d4-36aae89670c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_users,num_movies = urating_avg.shape[0],mrating_avg.shape[0]\n",
    "emb_size = 100\n",
    "model = CFModel(num_users,num_movies,emb_size).to(device)\n",
    "lr = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lambda_g = 0.1\n",
    "lambda_r = 0.1\n",
    "cfloss = CFLoss(lambda_g,lambda_r)\n",
    "\n",
    "nepochs = 20000\n",
    "print_every = 200\n",
    "rate_train_d = rate_train.to(device)\n",
    "indx_train_d = indx_train.to(device)\n",
    "rate_val_d = rate_val.to(device)\n",
    "indx_val_d = indx_val.to(device)\n",
    "model.train(True)\n",
    "for j in range(nepochs):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make predictions for this batch\n",
    "    uemb,memb = model()\n",
    "\n",
    "    # Compute the loss and its gradients\n",
    "    loss = cfloss(rate_train_d,uemb,memb,indx_train_d).to(device)\n",
    "    loss.backward()\n",
    "\n",
    "    # Adjust learning weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Gather data and report\n",
    "    last_loss = loss.item()\n",
    "    if j % print_every == 0:\n",
    "        model.eval()\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            uemb,memb = model()\n",
    "            loss = cfloss(rate_val_d,uemb,memb,indx_val_d).to(device)\n",
    "            print(f'epoch {j} train loss: {last_loss}, validation loss: {loss.item()}')\n",
    "\n",
    "        model.train(True)\n",
    "        # tb_x = epoch_index * len(training_loader) + i + 1\n",
    "        # tb_writer.add_scalar('Loss/train', last_loss, tb_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3890ade-baf5-4f7b-ab05-e892decf7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the list of movies with title and genre colums 5 to 23 with 1 if of that genre\n",
    "df_item = pd.read_csv('/home/giangi/Workspace/Data/ml-100k/u.item',sep='|',header=None,encoding='latin-1')\n",
    "#Read the mapping of the columns 5 to 25 to genre name\n",
    "df_genre_str = pd.read_csv('/home/giangi/Workspace/Data/ml-100k/u.genre',sep='|',header=None,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e834f4f-03f2-4c36-8961-cb99e6cb845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61144ec3-81f3-4b8a-8efd-0fbc9c7b7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69faf6",
   "metadata": {},
   "source": [
    "Movie might have multiple categories (genres), so just get one as representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017d676-e80b-4bf7-97b9-a4cdedf50152",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = [1]\n",
    "sel.extend(list(range(5,24)))\n",
    "i_genre = list(range(5,24))\n",
    "#select only the movie name and the gernes from df_item\n",
    "df_genre = df_item[sel]\n",
    "#get just one of the genre per move. Get the underlaying matrix of just movie genre\n",
    "dt_genre = df_genre[i_genre].values\n",
    "#get the index sorting along genre. The ones will always be last so get the index of last element\n",
    "col_gen = dt_genre.argsort(1)[:,-1]\n",
    "#Make sure only ones were selected\n",
    "np.unique(dt_genre[np.arange(len(col_gen)),col_gen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c51832-f6ce-4df2-b5ff-7267ea0fa9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26a28c-7fd6-4ad5-ac03-7a4d357660ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3150f3",
   "metadata": {},
   "source": [
    "col_gen cotains the numerical value of the genre which is also the index in df_genre_str. Select for each movie the genre name and numerical value from df_genre_str and concatenate the actual name of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa07bac-d172-4055-9499-6ac6c437dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_movie_genre = pd.concat([df_genre_str.loc[col_gen].reset_index(drop=True),df_genre[1]],axis=1,ignore_index=True)\n",
    "df_movie_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362c4c5",
   "metadata": {},
   "source": [
    "Group by the numerical values of the genre and get the mapping of each group, i.e. for each numerical genre which movie_ids belong to it. Print how many movies belong to each genre. Note that we assumed that a movie belong to only genre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec2301-042c-4530-8a8b-e7c59cee18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_indx = df_movie_genre.groupby(1).indices\n",
    "for k,v in movie_indx.items():\n",
    "    print(k,len(v),df_genre_str.loc[k].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5b566",
   "metadata": {},
   "source": [
    "Use tsne to do dimentionality reduction of the movies embeddings. One might expect that different genres are further apart in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d9d5e-8fa3-403d-bc4a-787f9b4dabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X = model.movie_emb.weight.detach().cpu().numpy()\n",
    "X_embedded = TSNE(n_components=3, learning_rate='auto',init='random', perplexity=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a90d8",
   "metadata": {},
   "source": [
    "Pick two genres that should not overlap like *Documentary* and *Horror* (7,11) or *Comedy* and *Drama* (5,8). Something like *Action* and *Adveture* might have both labels.  \n",
    "Rotate 3D figure to see if there is a view angle that shows one color more than the other (grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486af4e0-67d0-4a61-92f0-3cf6489bf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "mark = ['o','^']\n",
    "which = [5,8]\n",
    "i = 0\n",
    "for (k,v) in movie_indx.items():\n",
    "    if k in which:\n",
    "        ax.scatter(X_embedded[v,0],X_embedded[v,1],X_embedded[v,2],mark[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ea67a",
   "metadata": {},
   "source": [
    "Some sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c01703-3bfd-42d7-a64f-e0437ef8801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some manual verification to make sure the results are correct\n",
    "iuemb,imemb = model()\n",
    "uemb = iuemb.weight\n",
    "memb = imemb.weight\n",
    "#get the factorized matrix\n",
    "approx = torch.matmul(uemb,memb.T).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add279b-6e34-4f1b-8639-a61999146f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the validation set get the ones  whose predicted rating and < .5 from the truth\n",
    "sel = np.where(np.abs(approx[indx_val[:,0],indx_val[:,1]] - rate_val.numpy()) < .5)\n",
    "indx_good = indx_val[sel].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f33993-3171-4714-abe1-eaa3c7e7a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the difference is less than .5. Need to add back the avg_rate to compare\n",
    "np.abs(mratings.loc[indx[-(indx.size - split_train):][sel]]['rating'] - (approx[indx_good[:,0],indx_good[:,1]] + avg_rate.numpy())).max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c55c4586e5d8367157262f4649453ccda9ce6ed7633b9e450f38003cd2d34f54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
